{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sent(read_f, write_f, length):\n",
    "    with open(read_f, 'r') as f:\n",
    "        count = 0\n",
    "        for sent in f:\n",
    "            if count >= length:\n",
    "                break\n",
    "            with open(write_f, 'a+') as w:\n",
    "                if len(sent) > 1:\n",
    "                    w.write(sent)\n",
    "                    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_write_csv(csv_file, txt_file):\n",
    "    import pandas as pd\n",
    "    sent = []\n",
    "    label = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            sent.append(line)\n",
    "            label.append('n')\n",
    "    dataframe = pd.DataFrame({'sentence':sent, 'label':label})\n",
    "    dataframe.to_csv(csv_file, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "def sent_vector(csv_file, length):\n",
    "    if length > 0:\n",
    "        csv_data = pd.read_csv(csv_file, low_memory = False, nrows=length)#防止弹出警告\n",
    "    else:\n",
    "        csv_data = pd.read_csv(csv_file, low_memory = False)\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    sentences = csv_df['sentence']\n",
    "    label = csv_df['label']\n",
    "    label.loc[label == 'n'] = 0\n",
    "    label.loc[label == 'p'] = 1\n",
    "    model = word2vec.Word2Vec.load('Model/n1_cbow.w2v')\n",
    "    size = model.wv.syn0.shape[1]\n",
    "    sents_vec = []\n",
    "    for sent in sentences:\n",
    "        sents_vec.append(compute_sent_vec(sent, model, size))\n",
    "    return np.array(sents_vec), label, sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sent_vec(sent, model, size):\n",
    "    vec = np.zeros(size)\n",
    "    for word in sent.split():\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "    vec /= len(sent.split())\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/anaconda3/envs/acai/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "sents_vec, label, sentences = sent_vector('Data/training_data.csv', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost value is 0.6931471805599452\n",
      "cost value is 0.4683052304147046\n",
      "cost value is 0.43316134478005586\n",
      "cost value is 0.4150024601408376\n",
      "cost value is 0.40340038938895395\n",
      "cost value is 0.3953380750449278\n",
      "cost value is 0.389465815041177\n",
      "cost value is 0.38504807111637696\n",
      "cost value is 0.38164253115785424\n",
      "cost value is 0.3789662694465695\n",
      "正确率为82.16833095577746%\n"
     ]
    }
   ],
   "source": [
    "#self implemented logistic regression\n",
    "from classifier.logistic_regression import LogisticRegression\n",
    "l = LogisticRegression(sents_vec[:700], label[:700])\n",
    "cost = l.train(0.1,1000)\n",
    "pred_y = l.predict(sents_vec[300:], label[300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率为82.16833095577746%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/anaconda3/envs/acai/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#sklearn logistic regression result\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "label = np.array(label, dtype='int')\n",
    "clf = LogisticRegression(max_iter=1000).fit(sents_vec[:700], label[:700])\n",
    "test_accuracy = clf.score(sents_vec[300:], label[300:])*100\n",
    "pred = clf.predict(sents_vec[300:])\n",
    "print(\"正确率为%s%%\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self implemented k means\n",
    "from cluster.k_means import kMeans\n",
    "km = kMeans()\n",
    "centroids, sents_cluster = km.train(4, sents_vec[:1000], sentences[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['午安\\n',\n",
       " '跨跨 跨\\n',\n",
       " '丑 柑 19 了\\n',\n",
       " '跨 一下\\n',\n",
       " '呀呀 呀\\n',\n",
       " '撕家 宝宝\\n',\n",
       " '可怕 再 跨\\n',\n",
       " '自觉 跨 一个 🔥\\n',\n",
       " '黑 童话 既视感\\n',\n",
       " '丑   比多 作怪\\n',\n",
       " '跨 火盆\\n',\n",
       " '....\\n',\n",
       " '蠢蠢欲动\\n',\n",
       " '肚子饿\\n',\n",
       " '可爱 哇\\n',\n",
       " '弱国 无 外交 … …\\n',\n",
       " '— —\\n',\n",
       " '跨 🔥\\n',\n",
       " '好丑\\n',\n",
       " 'myss\\n',\n",
       " '跨 🔥\\n',\n",
       " '外星人 👽\\n',\n",
       " '😭 😭\\n',\n",
       " '好帅\\n',\n",
       " '浴衣 木屐 卷 毛毛 ~\\n',\n",
       " '钱包 干皮 惹\\n',\n",
       " '… …\\n',\n",
       " '看到 ps 痕迹 。 我 …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " 'i   like   it\\n',\n",
       " '踢 一脚\\n',\n",
       " 'https : m . weibo . cn52921076944127663834677764 肉 饱饱\\n',\n",
       " '.....\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '粗 脖怪   胖头鱼\\n',\n",
       " '北极星\\n',\n",
       " '围观 ！\\n',\n",
       " '戛纳\\n',\n",
       " '… …\\n',\n",
       " '… …\\n',\n",
       " '- - - - - -\\n',\n",
       " '老葛 今天 真的 突破 颜值 下限 了 … …\\n',\n",
       " '邪教\\n',\n",
       " 'zzf 这个 发型 … …\\n',\n",
       " '… …\\n',\n",
       " '嘴 … …\\n',\n",
       " '可怜 的 gg … …\\n',\n",
       " '____ （ （ （ （ （\\n',\n",
       " '____ （ （ （ （ （\\n',\n",
       " '- - -\\n',\n",
       " '____ （ （ （ （ （\\n',\n",
       " '脱饭 1128 秒\\n',\n",
       " '… …\\n',\n",
       " '马夫 丑受 整容 梅毒 人妖 丑干\\n',\n",
       " '小 太妹 既视感\\n',\n",
       " '史诗 级 吊粉\\n',\n",
       " '… …\\n',\n",
       " 'you   get   it 等艳玲\\n',\n",
       " '- - -\\n',\n",
       " '细 脖子   粗 脖怪   龟 丞相\\n',\n",
       " '吓人\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_cluster[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
