{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print(word2vec.FAST_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with open('Data/n_output.txt') as f:\n",
    "    for line in f:\n",
    "        sentence = []\n",
    "        for word in line.split():\n",
    "            sentence.append(word)\n",
    "        if len(sentence) > 1:\n",
    "            corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "#sg : {0, 1}, optional\n",
    "#Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "model = word2vec.Word2Vec(corpus, size=100, window=10, \n",
    "                          min_count=3,\n",
    "                          sg=0, hs=1, negative=20,\n",
    "                          workers=multiprocessing.cpu_count(), \n",
    "                          iter=20)\n",
    "model.save(\"Model/n_cbow.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "model = word2vec.Word2Vec(corpus, size=100, window=10, \n",
    "                          min_count=3,\n",
    "                          sg=1, hs=1, negative=20,\n",
    "                          workers=multiprocessing.cpu_count(), \n",
    "                          iter=20)\n",
    "model.save(\"Model/n_skip_gram.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = word2vec.Word2Vec.load('Model/cbow.w2v')\n",
    "n_cbow = word2vec.Word2Vec.load('Model/n_cbow.w2v')\n",
    "skip_gram = word2vec.Word2Vec.load('Model/skip_gram.w2v')\n",
    "n_skip_gram = word2vec.Word2Vec.load('Model/n_skip_gram.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cbow.wv.syn0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xw 0.7539643049240112\n",
      "他 0.6277556419372559\n",
      "表哥 0.618867039680481\n",
      "qx 0.612938404083252\n",
      "xk 0.588996171951294\n",
      "qq 0.5829169154167175\n",
      "jk 0.5627917647361755\n",
      "lw 0.5503636002540588\n",
      "gg 0.5446373224258423\n",
      "hgds 0.5424737930297852\n"
     ]
    }
   ],
   "source": [
    "for i in cbow.wv.most_similar(positive=['dw', '女朋友'], topn=10):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xw 0.7384853363037109\n",
      "他 0.641461968421936\n",
      "hgds 0.6348885297775269\n",
      "lw 0.6236293911933899\n",
      "gg 0.5918620824813843\n",
      "oo 0.5799072980880737\n",
      "她 0.5723540782928467\n",
      "wy 0.56436687707901\n",
      "女生 0.5557332634925842\n",
      "朋友 0.5552526116371155\n"
     ]
    }
   ],
   "source": [
    "for i in n_cbow.wv.most_similar(positive=['dw', '女朋友'],topn=10):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xw 0.7155860066413879\n",
      "他 0.7025020718574524\n",
      "绯闻 0.6453384757041931\n",
      "好想你—细思 0.6383764743804932\n",
      "xk 0.6301655769348145\n",
      "那 0.6278990507125854\n",
      "可是 0.6139957308769226\n",
      "越伤 0.6124129295349121\n",
      "因为 0.6113021373748779\n",
      "感觉 0.6101173162460327\n"
     ]
    }
   ],
   "source": [
    "for i in skip_gram.wv.most_similar(positive=['dw', '恋爱'], topn=10):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xw 0.7793722748756409\n",
      "他 0.6920454502105713\n",
      "wjk 0.6417802572250366\n",
      "她 0.6297566890716553\n",
      "说 0.6275898218154907\n",
      "gg 0.613830029964447\n",
      "还有 0.6095679998397827\n",
      "qx 0.6086161136627197\n",
      "之前 0.6062619686126709\n",
      "所以 0.6024121046066284\n"
     ]
    }
   ],
   "source": [
    "for i in n_skip_gram.wv.most_similar(positive=['dw', '女朋友'], topn=10):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
